{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db38fe5a-15ef-4ee9-bf7b-fa01b6918a38",
   "metadata": {},
   "source": [
    "# Agentic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f3047-0759-4cd5-85be-98f4740ff770",
   "metadata": {},
   "source": [
    "### pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbae4b-25df-47f8-8050-c260f3519d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yfinance langchain langchain_community langchain_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d12a29d-ea77-4106-b7c3-286fb8e6c1f8",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e584db8-f812-44aa-a0b4-34994fdbf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# tool to get the stock price of a stock quote\n",
    "def stock_market_tool(stock_quote: str):\n",
    "    # get the ticker\n",
    "    ticker = yf.Ticker(stock_quote)\n",
    "\n",
    "    # get the current stock_price\n",
    "    price = ticker.info['regularMarketPrice']\n",
    "\n",
    "    return {\"price\": price}    \n",
    "\n",
    "\n",
    "# create the metadata for the stock market tool\n",
    "stock_market_tool_metadata = {\n",
    "    \"name\": \"company_stock_price\",\n",
    "    \"description\": \"this tool is used to get the current stock price from stock market\",\n",
    "    \"arguments\": [{\"stock_quote\": \"stock ticker symbol for a company\"}],\n",
    "    \"response\": \"latest stock price of company\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c80b9dc-0d3f-4306-9ffc-d5876113249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool to get the current temperature/weather from a required city\n",
    "def weather_tool(city: str):\n",
    "    if city.lower() == \"pune\":\n",
    "        return {\"temperature\": 36}\n",
    "    elif city.lower() == \"mumbai\":\n",
    "        return {\"temperature\": 38}\n",
    "    elif city.lower() == \"satara\":\n",
    "        return {\"temperature\": 34}\n",
    "    else:\n",
    "        return \"not available\"\n",
    "\n",
    "# create the metadata for the weather tool\n",
    "weather_tool_metadata = {\n",
    "    \"name\": \"city_weather\",\n",
    "    \"description\": \"this tool is used to get the current temperature of required city\",\n",
    "    \"arguments\": [{\"city\": \"name of the city\"}],\n",
    "    \"response\": \"current temperature\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9832094-3243-42c2-94b4-6cdbb2f04546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the list of tools available\n",
    "tools = [stock_market_tool_metadata, weather_tool_metadata]\n",
    "\n",
    "# create the mapping between the tool name and its function\n",
    "tools_mapping = {\n",
    "    'city_weather': weather_tool,\n",
    "    'company_stock_price': stock_market_tool\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9fbcf-796a-447c-80ac-f3491dc8e9a4",
   "metadata": {},
   "source": [
    "### LLM configration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a00ce76-16a0-416f-9ca2-5c3a71914b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful assistant capable of answering questions on various topics. \n",
    "You must not use your internal knowledge or information to answer questions.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Think step-by-step to create a plan.\n",
    "Use only the following available tools to find information.\n",
    "Tools Available:\n",
    "\n",
    "{tools}\n",
    "Guidelines for Responses:\n",
    "\n",
    "Format 1: If the question cannot be answered with the available tools, use this format:\n",
    "{{\"answer\": \"No appropriate tool available\"}}\n",
    "\n",
    "Format 2: If you need to run tools to obtain the information, use this format:\n",
    "{{\"actions\": [{{ \"action\" : tool name, \"arguments\" : dictionary of argument values}}}}]\n",
    "\n",
    "Format 3: If you can answer the question using the responses from the tools, use this format:\n",
    "{{\"answer\": \"your response to the question\", \"explanation\": \"provide your explanation here\"}}\n",
    "\n",
    "\n",
    "Avoid any preamble; respond directly using one of the specified JSON formats.\n",
    "Question:\n",
    "\n",
    "{question}\n",
    "Tool Responses:\n",
    "\n",
    "{tool_responses}\n",
    "Your Response:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# create the prompt template\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "# create the llm model\n",
    "model = ChatOllama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "774e112b-ce5c-445a-8696-a127ae350cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_tool(response):\n",
    "    # get the result of every action\n",
    "    action_responses = []\n",
    "\n",
    "    # check if the response has at least an action present\n",
    "    if len(response['actions']) == 0:\n",
    "        print({\"answer\": \"question can not answered as there is no tool to answer the question\"})\n",
    "    else:\n",
    "        \n",
    "        # perform all the actions\n",
    "        for action in response['actions']:\n",
    "            \n",
    "            # get the function to invoke\n",
    "            function = tools_mapping[action['action']]\n",
    "\n",
    "            # pass the arguments and call the function\n",
    "            if type(action['arguments']) == list:\n",
    "                result = function(**action['arguments'][0])\n",
    "                action['response'] = result\n",
    "            elif type(action['arguments']) == dict:\n",
    "                result = function(**action['arguments'])\n",
    "                action['response'] = result\n",
    "\n",
    "            # collect the action with the result\n",
    "            action_responses.append(action)\n",
    "    \n",
    "    return action_responses "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753e4465-134a-4421-8628-26d94279e610",
   "metadata": {},
   "source": [
    "### step 1: get tool to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adcd92ee-f845-421d-9801-6b8f21517e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: \n",
      " {'actions': [{'action': 'company_stock_price', 'arguments': {'stock_quote': 'GOOG'}}]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "question = \"I have only $100, can I purchase 2 stocks of GOOG?\"\n",
    "\n",
    "# create the prompt\n",
    "prompt = prompt_template.invoke({\n",
    "    \"question\": question, \n",
    "    \"tools\": tools,\n",
    "    \"tool_responses\": \"\"\n",
    "})\n",
    "\n",
    "# get the answer from LLM\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "# convert the answer to the JSON\n",
    "response_json = json.loads(response.content)\n",
    "print(f\"STEP 1: \\n\", response_json, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb9eda-3dde-43cb-8d80-e98c9f831917",
   "metadata": {},
   "source": [
    "### step 2: invoke the tool and get the result           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4d6ddc3-872c-446d-940c-c61c5c26ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: \n",
      " [{'action': 'company_stock_price', 'arguments': {'stock_quote': 'AAPL'}, 'response': {'price': 219.9202}}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if we already have gottent the answer\n",
    "if 'answer' in response_json:\n",
    "    print(f\"got an answer: {response_json['answer']}\")\n",
    "elif 'actions' in response_json:\n",
    "    tool_responses = invoke_tool(response_json)\n",
    "    print(f\"STEP 2: \\n\", responses, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8604aa89-fd9c-4b34-a38a-a680bb529d42",
   "metadata": {},
   "source": [
    "### step 3: polish the result and present the answer to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1efc2f4a-b517-452c-9e89-83fd8431abd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"actions\": [\n",
      "   {\"action\": \"company_stock_price\", \n",
      "    \"arguments\": {\"stock_quote\": \"GOOG\"}\n",
      "   },\n",
      "   {\"action\": \"company_stock_price\", \n",
      "    \"arguments\": {\"stock_quote\": \"GOOG\"}\n",
      "   }\n",
      "]}\n",
      "\n",
      "Note: The available tool is 'company_stock_price' which returns the current stock price. To answer this question, I need to use this tool twice to get the current stock price of GOOG and then calculate if it's possible to purchase 2 stocks with $100.\n"
     ]
    }
   ],
   "source": [
    "# create the prompt\n",
    "prompt = prompt_template.invoke({\n",
    "    \"question\": question, \n",
    "    \"tools\": tools,\n",
    "    \"tool_responses\": response_json\n",
    "})\n",
    "\n",
    "# get the answer from LLM\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8438f3-2d40-4a3f-a6d7-64697d89aa51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
